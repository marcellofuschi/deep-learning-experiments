{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyBUUjw9S_tT"
      },
      "source": [
        "# Emotion analysis on chat messages, using transformers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UixJMrAbWfTj",
        "outputId": "42756ea8-5c01-4c7f-d1f3-2d7806983053"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HZRYJeAwS9KT"
      },
      "outputs": [],
      "source": [
        "CSV_DATASET_PATH = 'google_play_store_reviews.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ZHe1RU_wVwHp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import random_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5NFneR0dcdo"
      },
      "source": [
        "##Â Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "id": "oUZqw4wSXcKl",
        "outputId": "cd65a8db-0b1e-4c8c-90b6-a0cc96b6157b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples in the dataset: 12495\n",
            "\n",
            "                                             message sentiment\n",
            "0                      I cannot open the app anymore  negative\n",
            "1  I have been begging for a refund from this app...  negative\n",
            "2  Very costly for the premium version (approx In...  negative\n",
            "3  Used to keep me organized, but all the 2020 UP...  negative\n",
            "4                                Dan Birthday Oct 28  negative\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f60666002d0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def score_to_sentiment(rating):\n",
        "    rating = int(rating)\n",
        "    if rating <= 2:\n",
        "        return 'negative'\n",
        "    elif rating == 3:\n",
        "        return 'neutral'\n",
        "    else:\n",
        "        return 'positive'\n",
        "\n",
        "original_df = pd.read_csv(CSV_DATASET_PATH, sep=',')\n",
        "df = pd.DataFrame()\n",
        "df['message'] = original_df.content\n",
        "df['sentiment'] = original_df.score.apply(score_to_sentiment)\n",
        "df.dropna(inplace=True)\n",
        "del original_df\n",
        "\n",
        "print('Samples in the dataset:', df.shape[0], end='\\n\\n')\n",
        "print(df.head(), end='\\n\\n')\n",
        "df.groupby(['sentiment']).size().plot.bar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8RAwiNhWw29"
      },
      "source": [
        "## Test the tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TgYDc8hPWoQk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1917f99-7400-4191-ec57-19c2a95072e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  101,  2023,  2003,  1037, 24369,  7655,  1012,   102,     0,     0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])\n",
            "\n",
            "Decode of the generated tokens:\n",
            "[CLS] this is a dummy phrase. [SEP] [PAD] [PAD]\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "example_text = 'This is a dummy phrase.'\n",
        "bert_input = tokenizer(example_text, padding='max_length', max_length = 10, \n",
        "                       truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "print(bert_input['input_ids'])\n",
        "print(bert_input['token_type_ids'])\n",
        "print(bert_input['attention_mask'], end='\\n\\n')\n",
        "\n",
        "example_text = tokenizer.decode(bert_input.input_ids[0])\n",
        "print('Decode of the generated tokens:')\n",
        "print(example_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIr57imdqlsC"
      },
      "source": [
        "## Dataset class declaration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ZrLjVPMcjz2H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb3dfaa4-7334-40d7-8f23-2e20a72ff4f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels keys\n",
            "{'negative': 0, 'neutral': 1, 'positive': 2}\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# The tokenizer is used in order to store tokens instead of text in the Dataset instances.\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "SORTED_LABELS = sorted(df.sentiment.unique())  # We sort it because we want the labels order to be deterministic.\n",
        "LABELS_KEYS = {sentiment: key for (key, sentiment) in enumerate(SORTED_LABELS)}\n",
        "print('Labels keys', LABELS_KEYS, sep='\\n')\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df):\n",
        "        df.reset_index()\n",
        "        self.df = df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df['sentiment'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        assert(isinstance(idx, int))\n",
        "\n",
        "        text = self.df['message'].iloc[idx]\n",
        "        tokenized_text = self._tokenize_text(text)\n",
        "        \n",
        "        sentiment = self.df['sentiment'].iloc[idx]\n",
        "        y = np.array(LABELS_KEYS[sentiment])\n",
        "\n",
        "        return tokenized_text, y\n",
        "\n",
        "    def _tokenize_text(self, text):\n",
        "      return tokenizer(text, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U44K3pkwpCxT"
      },
      "source": [
        "## Declare class weights to fix dataset imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "3NZtSBUppBvt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b499774-d2d5-48fd-938d-fd67004f4c70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights: {'negative': 0.8587628602981567, 'neutral': 2.0919137001037598, 'positive': 0.7366465926170349}\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    'balanced',\n",
        "    classes = [LABELS_KEYS[sentiment] for sentiment in SORTED_LABELS],\n",
        "    y = [LABELS_KEYS[sentiment] for sentiment in df['sentiment']]\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "print('Class weights:', {sentiment: class_weights[LABELS_KEYS[sentiment]].item() for sentiment in SORTED_LABELS})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_G0gCdODZnCE"
      },
      "source": [
        "##Â Training, test, validation split\n",
        "Letâs split our dataframe into training, validation, and test set with the proportion of 80:10:10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "lyRWB_3aV61_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61be7c35-de81-407d-d81d-876ede8b2ba7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9996 1249 1250\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(112)\n",
        "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), [int(.8*len(df)), int(.9*len(df))])\n",
        "\n",
        "print(len(df_train), len(df_val), len(df_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NcXWpL0Y1zW"
      },
      "source": [
        "## Instantiate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6T9VzXgnY03f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a079176b-85e2-4626-f7e3-31789ea73369"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    num_labels=len(LABELS_KEYS),\n",
        "    classifier_dropout=0.3\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NL18zRhPyR_w"
      },
      "source": [
        "##Â Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPG_NgiTyAzk",
        "outputId": "50ea174f-0f02-4660-e2da-c1f1b8222d7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|ââââââââââ| 625/625 [15:14<00:00,  1.46s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1 | Train Loss:  0.052                 | Train Accuracy:  0.661                 | Validation Accuracy:  0.677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|ââââââââââ| 625/625 [15:19<00:00,  1.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 2 | Train Loss:  0.041                 | Train Accuracy:  0.746                 | Validation Accuracy:  0.721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|ââââââââââ| 625/625 [15:19<00:00,  1.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 3 | Train Loss:  0.035                 | Train Accuracy:  0.800                 | Validation Accuracy:  0.737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|ââââââââââ| 625/625 [15:19<00:00,  1.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 4 | Train Loss:  0.028                 | Train Accuracy:  0.847                 | Validation Accuracy:  0.738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|ââââââââââ| 625/625 [15:18<00:00,  1.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 5 | Train Loss:  0.021                 | Train Accuracy:  0.887                 | Validation Accuracy:  0.717\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|ââââââââââ| 625/625 [15:20<00:00,  1.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 6 | Train Loss:  0.016                 | Train Accuracy:  0.912                 | Validation Accuracy:  0.720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|ââââââââââ| 625/625 [15:20<00:00,  1.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 7 | Train Loss:  0.013                 | Train Accuracy:  0.936                 | Validation Accuracy:  0.738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|ââââââââââ| 625/625 [15:21<00:00,  1.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 8 | Train Loss:  0.011                 | Train Accuracy:  0.943                 | Validation Accuracy:  0.729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|ââââââââââ| 625/625 [15:20<00:00,  1.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 9 | Train Loss:  0.009                 | Train Accuracy:  0.954                 | Validation Accuracy:  0.718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|ââââââââââ| 625/625 [15:20<00:00,  1.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 10 | Train Loss:  0.007                 | Train Accuracy:  0.961                 | Validation Accuracy:  0.737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|ââââââââââ| 625/625 [15:19<00:00,  1.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 11 | Train Loss:  0.007                 | Train Accuracy:  0.964                 | Validation Accuracy:  0.733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|ââââââââââ| 625/625 [15:19<00:00,  1.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 12 | Train Loss:  0.006                 | Train Accuracy:  0.969                 | Validation Accuracy:  0.726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|ââââââââââ| 625/625 [15:19<00:00,  1.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 13 | Train Loss:  0.006                 | Train Accuracy:  0.971                 | Validation Accuracy:  0.741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|ââââââââââ| 625/625 [15:19<00:00,  1.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 14 | Train Loss:  0.005                 | Train Accuracy:  0.974                 | Validation Accuracy:  0.735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|ââââââââââ| 625/625 [15:18<00:00,  1.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 15 | Train Loss:  0.006                 | Train Accuracy:  0.972                 | Validation Accuracy:  0.725\n"
          ]
        }
      ],
      "source": [
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def train(model, train_data, val_data, learning_rate, epochs):\n",
        "    train, val = Dataset(train_data), Dataset(val_data)\n",
        "\n",
        "    BATCH_SIZE = 16\n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=BATCH_SIZE)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
        "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "        criterion = criterion.cuda()\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "        model.train()\n",
        "        epoch_train_accuracy = 0\n",
        "        epoch_train_loss = 0\n",
        "        for train_inputs, train_labels in tqdm(train_dataloader):\n",
        "            train_labels = train_labels.to(device)\n",
        "            mask = train_inputs[\"attention_mask\"].to(device)\n",
        "            input_id = train_inputs[\"input_ids\"].squeeze(1).to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(input_id, mask)\n",
        "            batch_loss = criterion(output.logits, train_labels)\n",
        "\n",
        "            batch_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_train_loss += batch_loss.item()\n",
        "            epoch_train_accuracy += (output.logits.argmax(dim=1) == train_labels).sum().item()\n",
        "\n",
        "        epoch_validation_accuracy = 0\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            for validation_inputs, validation_labels in val_dataloader:\n",
        "                validation_labels = validation_labels.to(device)\n",
        "                mask = validation_inputs[\"attention_mask\"].to(device)\n",
        "                input_id = validation_inputs[\"input_ids\"].squeeze(1).to(device)\n",
        "\n",
        "                output = model(input_id, mask)\n",
        "                epoch_validation_accuracy += (output.logits.argmax(dim=1) == validation_labels).sum().item()\n",
        "\n",
        "        print(\n",
        "            f\"Epochs: {epoch_num + 1} | Train Loss: {epoch_train_loss / len(train_data): .3f} \\\n",
        "                | Train Accuracy: {epoch_train_accuracy / len(train_data): .3f} \\\n",
        "                | Validation Accuracy: {epoch_validation_accuracy / len(val_data): .3f}\"\n",
        "        )\n",
        "\n",
        "\n",
        "EPOCHS = 15\n",
        "LR = 9e-6\n",
        "\n",
        "train(model, df_train, df_val, LR, EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-QoEaVkzBcl",
        "outputId": "0c57d549-d2d9-40a5-fcab-05a52a7a54fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy:  0.726\n"
          ]
        }
      ],
      "source": [
        "def evaluate(model, test_data):\n",
        "    dataloader = torch.utils.data.DataLoader(Dataset(test_data), batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "\n",
        "    test_accuracy = 0\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for test_inputs, test_labels in dataloader:\n",
        "            test_labels = test_labels.to(device)\n",
        "            mask = test_inputs['attention_mask'].to(device)\n",
        "            input_id = test_inputs['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "            output = model(input_id, mask)\n",
        "\n",
        "            test_accuracy += (output.logits.argmax(dim=1) == test_labels).sum().item()\n",
        "    \n",
        "    print(f'Test Accuracy: {test_accuracy / len(test_data): .3f}')\n",
        "    \n",
        "evaluate(model, df_test)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}