{"cells":[{"cell_type":"markdown","metadata":{"id":"ENdpIzLyycFw"},"source":["# Character-level LSTM with PyTorch\n","\n","An RNN model will be trained to generate new text character by character."]},{"cell_type":"code","source":["!pip install textstat"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iY7R0wQFBgpN","executionInfo":{"status":"ok","timestamp":1674913037762,"user_tz":-60,"elapsed":7612,"user":{"displayName":"Marcello Fuschi","userId":"01573905878399192715"}},"outputId":"345f3002-1de0-4178-ecef-0fb3f66fe894"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting textstat\n","  Downloading textstat-0.7.3-py3-none-any.whl (105 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 KB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyphen\n","  Downloading pyphen-0.13.2-py3-none-any.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pyphen, textstat\n","Successfully installed pyphen-0.13.2 textstat-0.7.3\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"tsoK1d67ycF1","executionInfo":{"status":"ok","timestamp":1674913040986,"user_tz":-60,"elapsed":3229,"user":{"displayName":"Marcello Fuschi","userId":"01573905878399192715"}}},"outputs":[],"source":["import numpy as np\n","import torch\n","from torch import nn\n","import torch.nn.functional as F"]},{"cell_type":"markdown","metadata":{"id":"JewJr-vMycF2"},"source":["## Training data"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"DP6f7VrkycF2","executionInfo":{"status":"ok","timestamp":1674913040986,"user_tz":-60,"elapsed":7,"user":{"displayName":"Marcello Fuschi","userId":"01573905878399192715"}}},"outputs":[],"source":["with open('html_physics_book.txt', 'r') as f:\n","    text = f.read()"]},{"cell_type":"markdown","metadata":{"id":"o-aoQoHIycF3"},"source":["### Characters tokenization\n","\n","We need to be able to convert each character into an integer token."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"_ylyruewycF3","executionInfo":{"status":"ok","timestamp":1674913040986,"user_tz":-60,"elapsed":5,"user":{"displayName":"Marcello Fuschi","userId":"01573905878399192715"}}},"outputs":[],"source":["chars_in_text = tuple(set(text))\n","\n","int2char = dict(enumerate(chars_in_text))\n","char2int = {ch: ii for ii, ch in int2char.items()}\n","\n","encoded_text = np.array([char2int[ch] for ch in text])"]},{"cell_type":"code","source":["# Encoding and then decoding produces the initial character\n","print(int2char[char2int['X']])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CsTcQHbOmIXW","executionInfo":{"status":"ok","timestamp":1674913041735,"user_tz":-60,"elapsed":754,"user":{"displayName":"Marcello Fuschi","userId":"01573905878399192715"}},"outputId":"ab029037-3a14-41d2-f066-af4f29979e49"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["X\n"]}]},{"cell_type":"markdown","metadata":{"id":"naZeJhL6ycF6"},"source":["The LSTM accepts only one-hot encoded vectors, so we prepare a function that takes as input an array of encoded characters and outputs an array of one-hot vectors."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Lyerrn0jycF7","executionInfo":{"status":"ok","timestamp":1674913041735,"user_tz":-60,"elapsed":9,"user":{"displayName":"Marcello Fuschi","userId":"01573905878399192715"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f3478879-d0c4-4bf8-e3ec-69979fc2ef54"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0.])"]},"metadata":{},"execution_count":6}],"source":["def to_one_hot(char_encoding):\n","    one_hot = np.zeros(len(int2char))\n","    one_hot[char_encoding] = 1\n","    return one_hot\n","\n","# Test\n","to_one_hot(12)"]},{"cell_type":"markdown","metadata":{"id":"_0fYgSq2ycF7"},"source":["## Making training mini-batches\n","\n","We want to create both the input and target arrays, with the targets being the same as the inputs, but shifted over one character."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"SPrN0R-aycF8","executionInfo":{"status":"ok","timestamp":1674913041736,"user_tz":-60,"elapsed":8,"user":{"displayName":"Marcello Fuschi","userId":"01573905878399192715"}}},"outputs":[],"source":["# Divide the `encodings_arr` array into batches.\n","def get_batches(encodings_arr, sequences_per_batch, chars_per_sequence):\n","    batch_size = sequences_per_batch * chars_per_sequence\n","    number_of_batches = len(encodings_arr)//batch_size\n","    \n","    # Keep only enough characters to make full batches\n","    encodings_arr = encodings_arr[:number_of_batches * batch_size]\n","    \n","    # Split the array into sequences by reshaping it into `sequences_per_batch` rows.\n","    encodings_arr = encodings_arr.reshape((sequences_per_batch, -1))\n","    \n","    for n in range(0, encodings_arr.shape[1], chars_per_sequence):        \n","        # The features\n","        x = encodings_arr[:, n:n+chars_per_sequence]\n","        \n","        # The targets, shifted by one\n","        y = np.zeros_like(x)\n","        \n","        try:\n","            y[:, :-1], y[:, -1] = x[:, 1:], encodings_arr[:, n+chars_per_sequence]\n","        except IndexError:\n","            y[:, :-1], y[:, -1] = x[:, 1:], encodings_arr[:, 0]\n","        \n","        yield x, y"]},{"cell_type":"markdown","source":["#### Test the mini-batches generation"],"metadata":{"id":"UVfu3TPeuPlU"}},{"cell_type":"code","source":["first_batch = next(get_batches(encoded_text, 3, 100))\n","print(f'Every mini-batch is a tuple of {len(first_batch)} arrays.')\n","print(f'First one contains features and in this case has shape {first_batch[0].shape}')\n","print(f'Second one contains targets and in this case has shape {first_batch[1].shape}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5RV7g3posJ77","executionInfo":{"status":"ok","timestamp":1674913041736,"user_tz":-60,"elapsed":8,"user":{"displayName":"Marcello Fuschi","userId":"01573905878399192715"}},"outputId":"2ebf6bfb-4906-4e30-c20a-682fb76877de"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Every mini-batch is a tuple of 2 arrays.\n","First one contains features and in this case has shape (3, 100)\n","Second one contains targets and in this case has shape (3, 100)\n"]}]},{"cell_type":"code","execution_count":9,"metadata":{"id":"uacfp0MMycF8","executionInfo":{"status":"ok","timestamp":1674913041736,"user_tz":-60,"elapsed":7,"user":{"displayName":"Marcello Fuschi","userId":"01573905878399192715"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3caeb4e0-5185-4334-d46f-eba4f70406ff"},"outputs":[{"output_type":"stream","name":"stdout","text":["x\n"," [[91 72 12 47 24 56 79 48 61 14]\n"," [ 8 13 39 14 65  8 13 39 46 14]\n"," [ 6 13 11 76 38 39 14  5 76 14]]\n","\n","y\n"," [[72 12 47 24 56 79 48 61 14 13]\n"," [13 39 14 65  8 13 39 46 14  8]\n"," [13 11 76 38 39 14  5 76 14  6]]\n"]}],"source":["x, y = first_batch\n","print('x\\n', x[:10, :10])\n","print('\\ny\\n', y[:10, :10])"]},{"cell_type":"markdown","metadata":{"id":"p5NJ0QTRycF9"},"source":["The data is correctly shifted over one step for `y`."]},{"cell_type":"markdown","metadata":{"id":"65etXbJ0ycF9"},"source":["---\n","## Model definition"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"PoanYVyPycF-","executionInfo":{"status":"ok","timestamp":1674913041736,"user_tz":-60,"elapsed":6,"user":{"displayName":"Marcello Fuschi","userId":"01573905878399192715"}}},"outputs":[],"source":["class CharRNN(nn.Module):\n","    def __init__(self, n_hidden=256, n_layers=2, drop_prob=0.5):\n","        super().__init__()\n","        self.n_layers = n_layers\n","        self.n_hidden = n_hidden\n","\n","        char_embedding_size = len(int2char) # size of the one-hot vectors representing characters\n","        self.lstm = nn.LSTM(char_embedding_size, n_hidden, n_layers, dropout=drop_prob, batch_first=True)\n","        self.dropout = nn.Dropout(drop_prob)\n","        self.fc = nn.Linear(n_hidden, char_embedding_size)\n","        \n","        self.init_weights()\n","      \n","    \n","    def forward(self, x, hc):\n","        # Get x, and the new hidden state (h, c) from the lstm\n","        x, (h, c) = self.lstm(x, hc)\n","        \n","        x = self.dropout(x)\n","        \n","        # Stack up LSTM outputs\n","        x = x.reshape(x.size()[0] * x.size()[1], self.n_hidden)\n","        \n","        x = self.fc(x)\n","        \n","        # Return x and the hidden state (h, c)\n","        return x, (h, c)\n","    \n","    \n","    def predict(self, char, h=None, cuda=False, top_k=None):\n","        ''' Given a character and the hidden state, predict the next character.\n","        \n","            Returns the predicted character and the new hidden state.\n","        '''\n","        if cuda:\n","            self.cuda()\n","        else:\n","            self.cpu()\n","        \n","        if h is None:\n","            h = self.init_hidden(1)\n","        \n","        x = np.array([[to_one_hot(char2int[char])]], dtype=np.float32)\n","        \n","        inputs = torch.from_numpy(x)\n","        \n","        if cuda:\n","            inputs = inputs.cuda()\n","        \n","        h = tuple([h_item.data for h_item in h])\n","        out, h = self.forward(inputs, h)\n","\n","        p = F.softmax(out, dim=1).data\n","        \n","        if cuda:\n","            p = p.cpu()\n","        \n","        if top_k is None:\n","            top_ch = np.arange(len(int2char))\n","        else:\n","            p, top_ch = p.topk(top_k)\n","            top_ch = top_ch.numpy().squeeze()\n","        \n","        p = p.numpy().squeeze()\n","        \n","        char = np.random.choice(top_ch, p=p/p.sum())\n","            \n","        return int2char[char], h\n","    \n","    def init_weights(self):\n","        self.fc.bias.data.fill_(0)\n","        self.fc.weight.data.uniform_(-1, 1)\n","        \n","    def init_hidden(self, n_seqs):\n","        ''' Initializes hidden state '''\n","        # Create two new tensors with sizes n_layers x n_seqs x n_hidden,\n","        # initialized to zero, for hidden state and cell state of LSTM\n","        weight = next(self.parameters()).data\n","        return (weight.new(self.n_layers, n_seqs, self.n_hidden).zero_(),\n","                weight.new(self.n_layers, n_seqs, self.n_hidden).zero_())\n","        "]},{"cell_type":"markdown","metadata":{"id":"3XWWejkPycF_"},"source":["## Network training"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"bOsuboWKycF_","executionInfo":{"status":"ok","timestamp":1674913041736,"user_tz":-60,"elapsed":6,"user":{"displayName":"Marcello Fuschi","userId":"01573905878399192715"}}},"outputs":[],"source":["def train(net, data, epochs=10, n_seqs=10, n_steps=50, lr=0.001, clip=5, val_frac=0.1, cuda=False, print_every=10):\n","    net.train()\n","    \n","    opt = torch.optim.Adam(net.parameters(), lr=lr)\n","    \n","    criterion = nn.CrossEntropyLoss()\n","    \n","    # create training and validation data\n","    val_idx = int(len(data)*(1-val_frac))\n","    data, val_data = data[:val_idx], data[val_idx:]\n","    \n","    if cuda:\n","        net.cuda()\n","    \n","    counter = 0\n","    \n","    for e in range(epochs):\n","        \n","        h = net.init_hidden(n_seqs)\n","        \n","        for x, y in get_batches(data, n_seqs, n_steps):\n","            \n","            counter += 1\n","            \n","            # One-hot encode our data and make them Torch tensors\n","            x = np.array([\n","                [to_one_hot(c) for c in seq] for seq in x\n","            ], dtype=np.float32)\n","            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n","            \n","            if cuda:\n","                inputs, targets = inputs.cuda(), targets.cuda()\n","\n","            # Creating new variables for the hidden state, otherwise\n","            # we'd backprop through the entire training history\n","            h = tuple([each.data for each in h])\n","\n","            net.zero_grad()\n","            \n","            output, h = net.forward(inputs, h)\n","            \n","            loss = criterion(\n","                output,\n","                targets.view(n_seqs*n_steps).type(torch.cuda.LongTensor if cuda else torch.LongTensor)\n","            )\n","\n","            loss.backward()\n","            \n","            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n","            nn.utils.clip_grad_norm_(net.parameters(), clip)\n","\n","            opt.step()\n","            \n","            if counter % print_every == 0:\n","                \n","                # Get validation loss\n","                val_h = net.init_hidden(n_seqs)\n","                val_losses = []\n","                \n","                for x, y in get_batches(val_data, n_seqs, n_steps):\n","                    \n","                    # One-hot encode our data and make them Torch tensors\n","                    x = np.array([\n","                        [to_one_hot(c) for c in seq] for seq in x\n","                    ], dtype=np.float32)\n","                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n","                    \n","                    # Creating new variables for the hidden state, otherwise\n","                    # we'd backprop through the entire training history\n","                    val_h = tuple([each.data for each in val_h])\n","                    \n","                    inputs, targets = x, y\n","                    if cuda:\n","                        inputs, targets = inputs.cuda(), targets.cuda()\n","\n","                    output, val_h = net.forward(inputs, val_h)\n","                    val_loss = criterion(\n","                        output,\n","                        targets.view(n_seqs*n_steps).type(torch.cuda.LongTensor if cuda else torch.LongTensor)\n","                    )\n","                \n","                    val_losses.append(val_loss.item())\n","                \n","                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n","                      \"Step: {}...\".format(counter),\n","                      \"Loss: {:.4f}...\".format(loss.item()),\n","                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T7PX3uPSycGB","executionInfo":{"status":"ok","timestamp":1674913041736,"user_tz":-60,"elapsed":4,"user":{"displayName":"Marcello Fuschi","userId":"01573905878399192715"}},"outputId":"8762684e-1062-40a9-8ad7-4a40e5517bb5"},"outputs":[{"output_type":"stream","name":"stdout","text":["CharRNN(\n","  (lstm): LSTM(94, 512, num_layers=2, batch_first=True, dropout=0.5)\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (fc): Linear(in_features=512, out_features=94, bias=True)\n",")\n"]}],"source":["net = CharRNN(n_hidden=512, n_layers=2)\n","\n","print(net)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"8NpfNmlHycGB","outputId":"5746fd2b-535d-42ab-8b8e-860b86493799"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 1/50... Step: 10... Loss: 3.6033... Val Loss: 3.6507\n","Epoch: 1/50... Step: 20... Loss: 3.4519... Val Loss: 3.4675\n","Epoch: 2/50... Step: 30... Loss: 3.3936... Val Loss: 3.4186\n","Epoch: 2/50... Step: 40... Loss: 3.3413... Val Loss: 3.3400\n","Epoch: 3/50... Step: 50... Loss: 3.2932... Val Loss: 3.2549\n","Epoch: 3/50... Step: 60... Loss: 3.2546... Val Loss: 3.1592\n","Epoch: 3/50... Step: 70... Loss: 3.1783... Val Loss: 3.0768\n","Epoch: 4/50... Step: 80... Loss: 3.1183... Val Loss: 2.9830\n","Epoch: 4/50... Step: 90... Loss: 3.0429... Val Loss: 2.9180\n","Epoch: 5/50... Step: 100... Loss: 2.9827... Val Loss: 2.8392\n","Epoch: 5/50... Step: 110... Loss: 2.8908... Val Loss: 2.7719\n","Epoch: 5/50... Step: 120... Loss: 2.8150... Val Loss: 2.7001\n","Epoch: 6/50... Step: 130... Loss: 2.7347... Val Loss: 2.6384\n","Epoch: 6/50... Step: 140... Loss: 2.6860... Val Loss: 2.6240\n","Epoch: 7/50... Step: 150... Loss: 2.6202... Val Loss: 2.5507\n","Epoch: 7/50... Step: 160... Loss: 2.5734... Val Loss: 2.5088\n","Epoch: 8/50... Step: 170... Loss: 2.5143... Val Loss: 2.4574\n","Epoch: 8/50... Step: 180... Loss: 2.4526... Val Loss: 2.4678\n","Epoch: 8/50... Step: 190... Loss: 2.4301... Val Loss: 2.4129\n","Epoch: 9/50... Step: 200... Loss: 2.4017... Val Loss: 2.3907\n","Epoch: 9/50... Step: 210... Loss: 2.3474... Val Loss: 2.3812\n","Epoch: 10/50... Step: 220... Loss: 2.3212... Val Loss: 2.3386\n","Epoch: 10/50... Step: 230... Loss: 2.3203... Val Loss: 2.3445\n","Epoch: 10/50... Step: 240... Loss: 2.2592... Val Loss: 2.3038\n","Epoch: 11/50... Step: 250... Loss: 2.2107... Val Loss: 2.2929\n","Epoch: 11/50... Step: 260... Loss: 2.2165... Val Loss: 2.2860\n","Epoch: 12/50... Step: 270... Loss: 2.2160... Val Loss: 2.2793\n","Epoch: 12/50... Step: 280... Loss: 2.2022... Val Loss: 2.2510\n","Epoch: 13/50... Step: 290... Loss: 2.1516... Val Loss: 2.2333\n","Epoch: 13/50... Step: 300... Loss: 2.0960... Val Loss: 2.2327\n","Epoch: 13/50... Step: 310... Loss: 2.0873... Val Loss: 2.2054\n","Epoch: 14/50... Step: 320... Loss: 2.1028... Val Loss: 2.1945\n","Epoch: 14/50... Step: 330... Loss: 2.0475... Val Loss: 2.1902\n","Epoch: 15/50... Step: 340... Loss: 2.0568... Val Loss: 2.1527\n","Epoch: 15/50... Step: 350... Loss: 2.0963... Val Loss: 2.1436\n","Epoch: 15/50... Step: 360... Loss: 2.0321... Val Loss: 2.1408\n","Epoch: 16/50... Step: 370... Loss: 1.9797... Val Loss: 2.1490\n","Epoch: 16/50... Step: 380... Loss: 2.0095... Val Loss: 2.1187\n","Epoch: 17/50... Step: 390... Loss: 1.9927... Val Loss: 2.1011\n","Epoch: 17/50... Step: 400... Loss: 2.0084... Val Loss: 2.0923\n","Epoch: 18/50... Step: 410... Loss: 1.9658... Val Loss: 2.0879\n","Epoch: 18/50... Step: 420... Loss: 1.9199... Val Loss: 2.0753\n","Epoch: 18/50... Step: 430... Loss: 1.9171... Val Loss: 2.0534\n","Epoch: 19/50... Step: 440... Loss: 1.9510... Val Loss: 2.0296\n","Epoch: 19/50... Step: 450... Loss: 1.8980... Val Loss: 2.0550\n","Epoch: 20/50... Step: 460... Loss: 1.9009... Val Loss: 2.0130\n","Epoch: 20/50... Step: 470... Loss: 1.9341... Val Loss: 2.0070\n","Epoch: 20/50... Step: 480... Loss: 1.8867... Val Loss: 1.9841\n","Epoch: 21/50... Step: 490... Loss: 1.8368... Val Loss: 1.9765\n","Epoch: 21/50... Step: 500... Loss: 1.8865... Val Loss: 1.9824\n","Epoch: 22/50... Step: 510... Loss: 1.8699... Val Loss: 1.9683\n","Epoch: 22/50... Step: 520... Loss: 1.8928... Val Loss: 1.9374\n","Epoch: 23/50... Step: 530... Loss: 1.8490... Val Loss: 1.9576\n","Epoch: 23/50... Step: 540... Loss: 1.8062... Val Loss: 1.9432\n","Epoch: 23/50... Step: 550... Loss: 1.8144... Val Loss: 1.9223\n","Epoch: 24/50... Step: 560... Loss: 1.8484... Val Loss: 1.8913\n","Epoch: 24/50... Step: 570... Loss: 1.7874... Val Loss: 1.9277\n","Epoch: 25/50... Step: 580... Loss: 1.7972... Val Loss: 1.8944\n","Epoch: 25/50... Step: 590... Loss: 1.8409... Val Loss: 1.9162\n","Epoch: 25/50... Step: 600... Loss: 1.7928... Val Loss: 1.8855\n","Epoch: 26/50... Step: 610... Loss: 1.7491... Val Loss: 1.8888\n","Epoch: 26/50... Step: 620... Loss: 1.7968... Val Loss: 1.9352\n","Epoch: 27/50... Step: 630... Loss: 1.7915... Val Loss: 1.8542\n","Epoch: 27/50... Step: 640... Loss: 1.7984... Val Loss: 1.8888\n","Epoch: 28/50... Step: 650... Loss: 1.7683... Val Loss: 1.8677\n","Epoch: 28/50... Step: 660... Loss: 1.7231... Val Loss: 1.8791\n","Epoch: 28/50... Step: 670... Loss: 1.7344... Val Loss: 1.8500\n","Epoch: 29/50... Step: 680... Loss: 1.7720... Val Loss: 1.8537\n","Epoch: 29/50... Step: 690... Loss: 1.7117... Val Loss: 1.8526\n","Epoch: 30/50... Step: 700... Loss: 1.7264... Val Loss: 1.8313\n","Epoch: 30/50... Step: 710... Loss: 1.7723... Val Loss: 1.8464\n","Epoch: 30/50... Step: 720... Loss: 1.7199... Val Loss: 1.8316\n","Epoch: 31/50... Step: 730... Loss: 1.6815... Val Loss: 1.8496\n","Epoch: 31/50... Step: 740... Loss: 1.7286... Val Loss: 1.8730\n","Epoch: 32/50... Step: 750... Loss: 1.7240... Val Loss: 1.8151\n","Epoch: 32/50... Step: 760... Loss: 1.7212... Val Loss: 1.8350\n","Epoch: 33/50... Step: 770... Loss: 1.7033... Val Loss: 1.8203\n","Epoch: 33/50... Step: 780... Loss: 1.6566... Val Loss: 1.8428\n","Epoch: 33/50... Step: 790... Loss: 1.6662... Val Loss: 1.8257\n","Epoch: 34/50... Step: 800... Loss: 1.7010... Val Loss: 1.8091\n","Epoch: 34/50... Step: 810... Loss: 1.6447... Val Loss: 1.8443\n","Epoch: 35/50... Step: 820... Loss: 1.6593... Val Loss: 1.8068\n","Epoch: 35/50... Step: 830... Loss: 1.7101... Val Loss: 1.8283\n","Epoch: 35/50... Step: 840... Loss: 1.6639... Val Loss: 1.8214\n","Epoch: 36/50... Step: 850... Loss: 1.6219... Val Loss: 1.7960\n","Epoch: 36/50... Step: 860... Loss: 1.6589... Val Loss: 1.8534\n","Epoch: 37/50... Step: 870... Loss: 1.6572... Val Loss: 1.8162\n","Epoch: 37/50... Step: 880... Loss: 1.6618... Val Loss: 1.8247\n","Epoch: 38/50... Step: 890... Loss: 1.6422... Val Loss: 1.8079\n","Epoch: 38/50... Step: 900... Loss: 1.5983... Val Loss: 1.7944\n","Epoch: 38/50... Step: 910... Loss: 1.6073... Val Loss: 1.7918\n","Epoch: 39/50... Step: 920... Loss: 1.6441... Val Loss: 1.8312\n","Epoch: 39/50... Step: 930... Loss: 1.5855... Val Loss: 1.7905\n","Epoch: 40/50... Step: 940... Loss: 1.6059... Val Loss: 1.7942\n","Epoch: 40/50... Step: 950... Loss: 1.6547... Val Loss: 1.7481\n","Epoch: 40/50... Step: 960... Loss: 1.6047... Val Loss: 1.8230\n","Epoch: 41/50... Step: 970... Loss: 1.5635... Val Loss: 1.7695\n","Epoch: 41/50... Step: 980... Loss: 1.5994... Val Loss: 1.8661\n","Epoch: 42/50... Step: 990... Loss: 1.6140... Val Loss: 1.7690\n","Epoch: 42/50... Step: 1000... Loss: 1.6134... Val Loss: 1.8203\n","Epoch: 43/50... Step: 1010... Loss: 1.5923... Val Loss: 1.7794\n","Epoch: 43/50... Step: 1020... Loss: 1.5434... Val Loss: 1.8248\n","Epoch: 43/50... Step: 1030... Loss: 1.5563... Val Loss: 1.8355\n","Epoch: 44/50... Step: 1040... Loss: 1.5878... Val Loss: 1.8144\n","Epoch: 44/50... Step: 1050... Loss: 1.5320... Val Loss: 1.8028\n","Epoch: 45/50... Step: 1060... Loss: 1.5504... Val Loss: 1.7892\n","Epoch: 45/50... Step: 1070... Loss: 1.5951... Val Loss: 1.8386\n","Epoch: 45/50... Step: 1080... Loss: 1.5618... Val Loss: 1.7900\n","Epoch: 46/50... Step: 1090... Loss: 1.5202... Val Loss: 1.8094\n","Epoch: 46/50... Step: 1100... Loss: 1.5549... Val Loss: 1.8202\n","Epoch: 47/50... Step: 1110... Loss: 1.5639... Val Loss: 1.7555\n","Epoch: 47/50... Step: 1120... Loss: 1.5600... Val Loss: 1.8059\n","Epoch: 48/50... Step: 1130... Loss: 1.5479... Val Loss: 1.7907\n","Epoch: 48/50... Step: 1140... Loss: 1.4885... Val Loss: 1.8430\n","Epoch: 48/50... Step: 1150... Loss: 1.5108... Val Loss: 1.8262\n","Epoch: 49/50... Step: 1160... Loss: 1.5406... Val Loss: 1.7958\n","Epoch: 49/50... Step: 1170... Loss: 1.4755... Val Loss: 1.8378\n","Epoch: 50/50... Step: 1180... Loss: 1.5025... Val Loss: 1.7664\n"]}],"source":["train(\n","    net,\n","    encoded_text,\n","    epochs=50,\n","    n_seqs=128,\n","    n_steps=300,\n","    lr=3e-4,\n","    cuda=torch.cuda.is_available(),\n","    print_every=10\n",")"]},{"cell_type":"markdown","metadata":{"id":"wGi6nN03ycGC"},"source":["After training, we'll save the model so we can load it again later if we need to."]},{"cell_type":"code","execution_count":17,"metadata":{"id":"08NxMviGycGC","executionInfo":{"status":"ok","timestamp":1674914047047,"user_tz":-60,"elapsed":651,"user":{"displayName":"Marcello Fuschi","userId":"01573905878399192715"}}},"outputs":[],"source":["checkpoint = {'n_hidden': net.n_hidden,\n","              'n_layers': net.n_layers,\n","              'state_dict': net.state_dict()}\n","\n","with open('trained_model.net', 'wb') as f:\n","    torch.save(checkpoint, f)"]},{"cell_type":"markdown","metadata":{"id":"kMIfAIVzycGC"},"source":["## Sampling\n","\n","To sample from the trained model, we pass in a character and have the network predict the next character. Then we take that character, pass it back in, and get another predicted character. By keeping doing this we'll generate a bunch of text.\n","\n","### Top K sampling\n","\n","Our predictions come from a categorical probability distribution over all the possible characters. We can make the sample text and make it more reasonable to handle (with less variables) by only considering some $K$ most probable characters. This will prevent the network from giving us completely absurd characters while allowing it to introduce some noise and randomness into the sampled text.\n","\n","In general the first bunch of characters will be a little rough since it hasn't built up a long history of characters to predict from."]},{"cell_type":"code","execution_count":18,"metadata":{"id":"gbzwujN-ycGC","executionInfo":{"status":"ok","timestamp":1674914063696,"user_tz":-60,"elapsed":362,"user":{"displayName":"Marcello Fuschi","userId":"01573905878399192715"}}},"outputs":[],"source":["def generate_sample(net, sample_length, prime='<div>', top_k=None, cuda=False):\n","    if cuda:\n","        net.cuda()\n","    else:\n","        net.cpu()\n","\n","    net.eval()\n","    \n","    # First off, run through the prime characters\n","    chars = [ch for ch in prime]\n","    \n","    h = net.init_hidden(1)\n","    \n","    for ch in prime:\n","        char, h = net.predict(ch, h, cuda=cuda, top_k=top_k)\n","\n","    chars.append(char)\n","    \n","    for ii in range(sample_length):\n","        char, h = net.predict(chars[-1], h, cuda=cuda, top_k=top_k)\n","        chars.append(char)\n","\n","    return ''.join(chars)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"U7sL3pHUycGC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674914068962,"user_tz":-60,"elapsed":4782,"user":{"displayName":"Marcello Fuschi","userId":"01573905878399192715"}},"outputId":"e225439a-146e-4e43-ce84-fc4217505722"},"outputs":[{"output_type":"stream","name":"stdout","text":["<div>\n","           </p>\n","      </i>\n","      </p>\n","    <h4>Important Topiss</h4>\n","    <p>16. At that a storce of the sercaly of a pliseding an the maghet the camper subentins the contens of whine the cirmen supents ander and teren to tome tount to the farment to be the sures of whell whice it cust of the caler it of enely in the pondere the ponction is a colles than a porend calle ot an ilachod ator the simcens of the millo to ater inderenting the plessupe of thromes thas tore ated to cand to a pan at in o serant it in suched to thres, at ar plactivice the fremens of the rengition and of the sumen ones is of the ratsument of what the sictions a calterace for the mare of a surto is caller to ater, the cearse than of the reftenting the conconter conser silling antele work whac it cormatusting the somperition. The collents thas that in to te sorman at recusters of to the perance ater to than a conducin of whice the conture of a conse tho ele the soull to thic the selistric formeng a forment is. </span>\n","    </div>\n","    <p>\n","      <b>17. Exeltions <span class=\"label\">\n","          <a href=\"#Page_43\" i>=</a>\n","        </p>\n","    </div>\n","    <p>This tire of a to teen it. The prometed in a currat it a porition of this ins the comeren the sored ar ores as a thenderer ther in the coneraced is the plater in store of the mighting ins the eramporition to the chantary the simperes the elowend in the sore compicat as armight it croution. If to section of expensed, work the colled in the and to thes ene cors te the poresing to bo water atounts the soule the round the erection. The roution out the renting.</p>\n","    <p>2. What is alectrisecting as and carestar estely of a the carment is of contection in this is curffeced betwones in sure fich thes of the cond of in the ponting pan as alore the ston is ance the comports of the pare curron the simpont an and in the sumon the resplesed the prosint compartent. It is the expantice of with a deas the plater is that asce of ar aldoration.</p>\n","    <p>3. If the stricely the rates the serenter, the siment of thet in the roples arouled and the reartiol on the some ins corsumes that of the andirg pesten of will by inticis the pared that it shat in thrige porings inse the reftence is the election the refining a fired tormeter, the cisten that the mane to pens are one is te serce and conte car enetror or in the plige and a the sumpanions, is comper the comer a digh to ster ase for mate fired an aro a sele the caind to the firen the sound. Wark in which is an the curfinces in the recure the serter astang of curretser through sound of the sireculle the raghe to sto cens aron of the colecter of the sill cond to as aro thans is of a sencited in tho weich surrowing by the reat the ficin in a policelly in of the plinge of the panters in a polesing and tromure of the carmenter to buter this forte are toul as ate of the somont in tom sured the sones is a condicat isce the cance of the reation of the corece in the reficion a sere to sume a forcul bot an electromed celling thet water, water is current of the prons ond is a pond atomet the electric cirranted or prosecter are are in the porting in o that and tron thot the rumin are of the sirallidy is and wo light it in the routed be of a that where the rater it it and the pars ore produces of whar in ascerat iscuntations of expenisedy by the mant offte cillon a dichingen of the caisid anc is a tone consing is colles a pond tur efficing.</p>\n","    <p>4. In the rustanting it in called bolles ind ther is a charge of e the pontance is the sormeration as or a cunter of enter of the concuss and of a to man is and a brometer.</td>\n","        </tr>\n","        <tr>\n","          <td align=\"left\">C.</td>\n","        </td>\n","        <tt>\n","          <td align=\"left\">10</ts>\n","          <td align=\"left\"> terentens and and of the secar ento tho warg the sercular the sulin trosuct that the precurt of the sincar and intone then a cound of the ressuled the ponsesto corvere somenst and ot is surfiter the somer is and the surfieled \n"]}],"source":["sample = generate_sample(net, 4000, top_k=5, cuda=True)\n","\n","print(sample)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}